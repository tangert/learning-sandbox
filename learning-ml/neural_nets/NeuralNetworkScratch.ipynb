{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to take an object oriented approach and make this as intuitive as possible.\n",
    "Probably going to test this out on MNIST, then will convert it into a Tensorflow NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        # MARK: Layers\n",
    "        # Each layer is an array of Neuron objects\n",
    "        self.input_layer = Layer(input_size)\n",
    "        self.hidden_layer = Layer(hidden_size)\n",
    "        self.output_layer = Layer(output_size)\n",
    "        \n",
    "        # define a larger object which contains all layers\n",
    "        self.layers = [self.input_layer,\n",
    "                       self.hidden_layer,\n",
    "                       self.output_layer]\n",
    "        \n",
    "        # MARK: Synapses\n",
    "        # input -> hidden layer synapses\n",
    "        # shape: input size x hidden size\n",
    "        # why? for every input, we connect it to a hidden neuron.\n",
    "        # if we want a matrix to represent all of the weights of the synapses,\n",
    "        # then \n",
    "        self.input_hidden_synapses = Synapses(input_size, hidden_size)\n",
    "        \n",
    "        # hidden -> output synapses\n",
    "        self.hidden_output_synapses = Synapses(hidden_size, output_size)\n",
    "    \n",
    "    def train(self, epochs, learning_rate):\n",
    "        return 0\n",
    "    \n",
    "    def forward_propogate(self, data, use_mm=False):\n",
    "        \n",
    "        # if using matrix multiplication (mm):\n",
    "        if use_mm:\n",
    "            return 0\n",
    "        \n",
    "        # otherwise, manually compute the sums of weights/inputs in each neuron\n",
    "        \n",
    "        # first pass the data from the input neurons to the hidden layer\n",
    "        # multiply all of the inputs by their respective weights\n",
    "        # add them up at each neuron\n",
    "        # pass that through the activation function\n",
    "            # you can call the function on an entire matrix\n",
    "        \n",
    "        #second pass that new number and multiply by second set of weights\n",
    "        # add all of them up in the ouput neuron\n",
    "        # apply the activation one more time\n",
    "        # that's your answer!\n",
    "        \n",
    "        # first implement it manually with scalar multiplication \n",
    "        # then show how it's done with matrix multiplication\n",
    "    \n",
    "    def backward_propogate():\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Stores a list of neurons\n",
    "    Initialized with the number of neurons in the layer\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.neurons = [Neuron() for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Takes in data and applies an activation function to pass to the next layer\n",
    "    \"\"\"        \n",
    "    def process_input(weights, inputs):\n",
    "        # performs matrix multiplication between the weights and the inputs\n",
    "        # then passes it to the activation function\n",
    "        return 0\n",
    "    \n",
    "    # activation sigmoid function\n",
    "    # takes in the summed weights * inputs\n",
    "    def activate(self, x, deriv=False):\n",
    "        if deriv:\n",
    "            return x*(1-x)\n",
    "        return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synapses:\n",
    "    \"\"\" \n",
    "    The connections in between layers\n",
    "    Represented as a matrix of weights\n",
    "    \"\"\"\n",
    "    def __init__(self, rows, colums):\n",
    "        # this initializes the weights to a random Column-d array\n",
    "        self.weights = np.random.randn(rows, colums)\n",
    "    \n",
    "    # updates the weights\n",
    "    def update():\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example network \n",
    "nn = NeuralNetwork(input_size=2,\n",
    "                   hidden_size=3,\n",
    "                   output_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
