{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to take an object oriented approach and make this as intuitive as possible.\n",
    "Probably going to test this out on MNIST, then will convert it into a Tensorflow NN.\n",
    "\n",
    "Note: this is not a self-contained tutorial on how neural networks work but I explain why certain functions are the way they are for clarity's sake. I will assume anyone using this for self-education purposes has read about the basic structure of neural networks/perceptrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data length: 70000\n",
      "Training data length: 56000\n",
      "Testing data length: 14000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the MNIST dataset\n",
    "Contains 70,000 examples of hand-written digits in 28x28 pixel form (784)\n",
    "\"\"\"\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "# The original data\n",
    "# Stored as a 70,000 x 784 array\n",
    "data = mnist[\"data\"]\n",
    "\n",
    "# Take first 80% for training, last 20% for testing\n",
    "training_data = data[0 : math.floor(len(data)*0.8)]\n",
    "testing_data = data[math.floor(len(data)*0.8) : len(data)]\n",
    "\n",
    "print(\"Total data length:\",len(data))\n",
    "print(\"Training data length:\",len(training_data))\n",
    "print(\"Testing data length:\",len(testing_data))\n",
    "\n",
    "# The target labels for classifying the data\n",
    "# [0,1,2,3,4,5,6,7,8,9]\n",
    "targets = mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    A simple feed forward neural network\n",
    "    \n",
    "    The goal here is to abstract each component of the network (neuron, layer, synapses)\n",
    "    to a high level to easily visualize how the network operates and how it trains\n",
    "    \n",
    "    The network records the state of the weights/neurons at each epoch and exports\n",
    "    a JSON file representing the entire training process\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the network given input layer,\n",
    "        hidden layer, and output layer neuron size\n",
    "        \"\"\"\n",
    "        \n",
    "        # LAYERS\n",
    "        # Each layer is an array of Neuron objects\n",
    "        self.input_layer = Layer(input_size)\n",
    "        self.hidden_layer = Layer(hidden_size)\n",
    "        self.output_layer = Layer(output_size)\n",
    "        \n",
    "        # Define a larger object which contains all layers\n",
    "        self.layers = [self.input_layer,\n",
    "                       self.hidden_layer,\n",
    "                       self.output_layer]\n",
    "        \n",
    "        # SYNAPSES\n",
    "        # input -> hidden layer synapses\n",
    "        self.input_to_hidden_synapses = Synapses(input_size, hidden_size)\n",
    "        \n",
    "        # hidden -> output synapses\n",
    "        self.hidden_to_output_synapses = Synapses(hidden_size, output_size)\n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    # MARK: Training and processing functions\n",
    "    #########################################\n",
    "    \n",
    "    def train(self, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Trains the network\n",
    "        \n",
    "        Epochs: the number of iterations\n",
    "        Learning rate: the size of the \"steps\" that gradient descent takes\n",
    "            - higher learning rate means larger steps but also risks\n",
    "              \"overstepping\" the minimum of the curve\n",
    "            - low learning rate is more precise but calculating the gradient itself\n",
    "              is computationally expensive so there is a good middle ground\n",
    "        \"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def forward_propogate(self, data, using_matrix_multiplication=True):\n",
    "        \"\"\"\n",
    "        Passes an input data vector (an image grid, a list of tuples, etc) through\n",
    "        the network and outputs a prediction from the output layer\n",
    "        \"\"\"\n",
    "        # matrix multiplication allows us to compute weight x input calculations\n",
    "        # in large batches and is super efficient\n",
    "        if using_matrix_multiplication:\n",
    "            return 0\n",
    "        \n",
    "        # otherwise, manually compute the sums of weights/inputs in each neuron\n",
    "        \n",
    "        # first pass the data from the input neurons to the hidden layer\n",
    "        # multiply all of the inputs by their respective weights\n",
    "        # add them up at each neuron\n",
    "        # pass that through the activation function\n",
    "            # you can call the function on an entire matrix\n",
    "        \n",
    "        #second pass that new number and multiply by second set of weights\n",
    "        # add all of them up in the ouput neuron\n",
    "        # apply the activation one more time\n",
    "        # that's your answer!\n",
    "        \n",
    "        # first implement it manually with scalar multiplication \n",
    "        # then show how it's done with matrix multiplication\n",
    "    \n",
    "    def backward_propogate(self):\n",
    "        \"\"\"\n",
    "        Updates the weights of the network based on training data to make the\n",
    "        network more accurate\n",
    "        \"\"\"\n",
    "        return 0\n",
    "    \n",
    "    ##########################################\n",
    "    # MARK: Export and visualization functions\n",
    "    ##########################################\n",
    "    \n",
    "    def export_network(self):\n",
    "        \"\"\"\n",
    "        Exports the network as a list of objects that\n",
    "        represent the entire state of the network\n",
    "        \n",
    "        Can use this for visualization purposes\n",
    "        \n",
    "        1. Network object: \n",
    "        {\n",
    "            input_neurons: [], -> doesn't change with training\n",
    "            training_states: [\n",
    "                { State 1 }, \n",
    "                { State 2 },\n",
    "                { State 3 },\n",
    "                ...\n",
    "                { State n (n = number of epochs) }\n",
    "            ],\n",
    "            output_neurons: [] -> doesn't change with training\n",
    "        }\n",
    "        \n",
    "            State object:\n",
    "            #note: only needs to include the variables that change\n",
    "            {\n",
    "                 input_to_hidden_synapses: [], -> matrix of weights\n",
    "                 hidden_to_output_synapses: [], -> matrix of weights\n",
    "                 hidden_layer: [] -> list of tuples: (sum, activated_sum)\n",
    "            }\n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Stores a list of neurons\n",
    "    Initialized with the number of neurons in the layer\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.neurons = [Neuron() for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Takes in data and applies an activation function to pass to the next layer\n",
    "    \n",
    "    These functions are really only used if we don't use matrix multiplication to\n",
    "    do all of the operations at once...\n",
    "    \n",
    "    But it's important to understand how this is happening on an individual-neuron level\n",
    "    \"\"\"\n",
    "    \n",
    "    # 'all_values' stores all of the previous values for visualization\n",
    "    # Format: [(sum, activated_sum)] list of tuples containing the sum, then activated sum\n",
    "    # This way we can visualize the process of the data actually being passed into the neuron\n",
    "    # and then being processed\n",
    "    \n",
    "    all_values = []\n",
    "    \n",
    "    def process_input(weights, inputs):\n",
    "        \"\"\"\n",
    "        performs matrix multiplication between the weights and the inputs\n",
    "        then passes it to the activation function\n",
    "        \"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def activate(self, x, deriv=False):\n",
    "        \"\"\"\n",
    "        activation sigmoid function\n",
    "        takes in the summed weights * inputs\n",
    "        \"\"\"\n",
    "        if deriv:\n",
    "            return x*(1-x)\n",
    "        return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synapses:\n",
    "    \"\"\" \n",
    "    The connections in between layers\n",
    "    Represented as a matrix of weights\n",
    "    \n",
    "    The synapses store all of its previous weights to visualize the training process\n",
    "    \"\"\"\n",
    "    def __init__(self, rows, colums):\n",
    "        # this initializes the weights to a random Column-d array\n",
    "        self.weights = np.random.randn(rows, colums)\n",
    "    \n",
    "    # updates the weights\n",
    "    def update():\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example network \n",
    "nn = NeuralNetwork(input_size=2,\n",
    "                   hidden_size=3,\n",
    "                   output_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
