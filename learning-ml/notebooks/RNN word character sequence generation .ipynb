{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN word prediction \n",
    "Building a Vanilla RNN and LSTM in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/pg.txt\"\n",
    "raw_text = open(filepath).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the characters to unique indexes\n",
    "These dictionaries are used to:\n",
    "1) Transform all words into a series of one-hot encoded vectors\n",
    "2) Transform vectorized predictions back into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', '1', '[', '_', '.', 't', '(', 'c', 'g', 'j', 'x', 'i', 'o', ';', \"'\", '2', '9', 'w', '5', 'e', ' ', '?', '-', 'â€”', 'n', '0', ',', 'k', 'v', 'a', ']', ':', 'm', 'r', 'y', 'l', 'p', 'd', 'u', '$', '3', '\\n', 'h', 'b', '\"', 'z', 'f', '6', 's', '8', '4', '%']\n"
     ]
    }
   ],
   "source": [
    "# unique chars present in the data set\n",
    "vocab = list(set(raw_text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2int = { c:i for i,c in enumerate(vocab) }\n",
    "int2ch = { i:c for i,c in enumerate(vocab) }\n",
    "num_chars, num_vocab = len(raw_text), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 49993, total vocab: 52\n"
     ]
    }
   ],
   "source": [
    "print(\"Total chars: {}, total vocab: {}\".format(num_chars, num_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data\n",
    "We essentially have to decide up front how long each sequence of inputs is. How many time steps do you predict through one forward pass of the network?\n",
    "\n",
    "Let's just choose 255, since that's the length of a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns:  49738\n",
      "[5, 42, 19, 20, 11, 24, 28, 19, 48, 5, 12, 33, 48, 20, 48, 12, 20, 32, 38, 7, 42, 20, 29, 43, 12, 38, 5, 20, 5, 42, 19, 11, 33, 20, 48, 5, 29, 33, 5, 38, 36, 20, 42, 38, 43, 48, 4, 20, 20, 29, 48, 20, 29, 20, 35, 12, 5, 20, 12, 46, 20, 32, 11, 24, 37, 20, 11, 20, 37, 12, 24, 14, 5, 20, 27, 24, 12, 17, 20, 5, 42, 19, 20, 32, 12, 33, 19, 20, 29, 11, 33, 43, 12, 33, 24, 11, 24, 8, 20, 7, 29, 48, 19, 20, 12, 46, 20, 5, 42, 19, 20, 19, 38, 33, 12, 36, 19, 29, 24, 20, 12, 46, 20, 5, 42, 19, 20, 48, 7, 42, 19, 37, 38, 35, 19, 26, 20, 29, 24, 37, 20, 46, 33, 12, 32, 20, 48, 38, 7, 42, 20, 48, 11, 5, 19, 48, 20, 5, 42, 29, 5, 20, 17, 12, 38, 35, 37, 20, 43, 19, 20, 5, 42, 29, 5, 20, 29, 20, 35, 12, 17, 20, 11, 37, 19, 29, 20, 46, 12, 33, 20, 32, 12, 24, 19, 34, 20, 17, 19, 14, 33, 19, 20, 24, 12, 5, 20, 11, 24, 20, 29, 24, 8, 19, 35, 20, 33, 12, 38, 24, 37, 48, 4, 20, 5, 42, 19, 20, 17, 12, 33, 35, 37, 20, 29, 33, 19, 20, 5, 42, 19, 20, 37, 29, 24, 8, 19, 33, 20, 5, 42, 29, 5, 20, 32]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "seq_length = 255\n",
    "\n",
    "# Input data stores the 255 character sequences\n",
    "input_data = []\n",
    "\n",
    "# Output data stores the predicted characters\n",
    "output_data = []\n",
    "\n",
    "# populate both of them\n",
    "# we stop at num_chars - seq_length because that is the last\n",
    "# pattern we will need to recognize\n",
    "for i in range(num_chars - seq_length):\n",
    "    \n",
    "    # the \"sliding window\" of characters\n",
    "    # these are basically 255-grams\n",
    "    input_seq = raw_text[i:i+seq_length]\n",
    "    output_prediction = raw_text[i+seq_length]\n",
    "    \n",
    "    input_data.append([ch2int[ch] for ch in input_seq])\n",
    "    output_data.append(ch2int[output_prediction])\n",
    "\n",
    "num_patterns = len(input_data)\n",
    "print(\"Number of patterns: \", num_patterns)\n",
    "\n",
    "print(input_data[0])\n",
    "print(output_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the data for input into Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new shape: samples, time steps, features\n",
    "\n",
    "reshaped_input = np.reshape(input_data, (num_patterns, seq_length, 1))\n",
    "\n",
    "# normalize each of the inputs by the number of characters\n",
    "# sort of a \"character gradient\n",
    "reshaped_input = reshaped_input / (num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49738, 255, 1)\n"
     ]
    }
   ],
   "source": [
    "# Translation here: \n",
    "# This is a list of ALL \"255-grams\",\n",
    "# of length 255, where each one is represented by\n",
    "# a list of 1D normalized character values.\n",
    "\n",
    "print(reshaped_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_output = np_utils.to_categorical(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non vectorized:  24\n",
      "Vectorized:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Non vectorized: \", output_data[2])\n",
    "print(\"Vectorized: \", onehot_output[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, a vanilla RNN\n",
    "\n",
    "VanillaModel = Sequential()\n",
    "VanillaModel.add(SimpleRNN(256, input_shape=(reshaped_input.shape[1], reshaped_input.shape[2])))\n",
    "VanillaModel.add(Dropout(0.2))\n",
    "VanillaModel.add(Dense(onehot_output.shape[1], activation='softmax'))\n",
    "VanillaModel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Then, an LSTM\n",
    "LSTMModel = Sequential()\n",
    "LSTMModel.add(LSTM(256, input_shape=(reshaped_input.shape[1], reshaped_input.shape[2])))\n",
    "LSTMModel.add(Dropout(0.2))\n",
    "LSTMModel.add(Dense(onehot_output.shape[1], activation='softmax'))\n",
    "LSTMModel.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the weight improvements as you train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "weightfile = \"weights-LSTM-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weightfile, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49738/49738 [==============================] - 74s 1ms/step - loss: 2.9390\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.93904, saving model to weights-improvement-01-2.9390.hdf5\n",
      "Epoch 2/20\n",
      "49738/49738 [==============================] - 72s 1ms/step - loss: 2.8492\n",
      "\n",
      "Epoch 00002: loss improved from 2.93904 to 2.84919, saving model to weights-improvement-02-2.8492.hdf5\n",
      "Epoch 3/20\n",
      "49738/49738 [==============================] - 70s 1ms/step - loss: 2.8288\n",
      "\n",
      "Epoch 00003: loss improved from 2.84919 to 2.82878, saving model to weights-improvement-03-2.8288.hdf5\n",
      "Epoch 4/20\n",
      "49738/49738 [==============================] - 70s 1ms/step - loss: 2.8201\n",
      "\n",
      "Epoch 00004: loss improved from 2.82878 to 2.82008, saving model to weights-improvement-04-2.8201.hdf5\n",
      "Epoch 5/20\n",
      "49738/49738 [==============================] - 71s 1ms/step - loss: 2.9855\n",
      "\n",
      "Epoch 00005: loss did not improve from 2.82008\n",
      "Epoch 6/20\n",
      "49738/49738 [==============================] - 70s 1ms/step - loss: 3.3043\n",
      "\n",
      "Epoch 00006: loss did not improve from 2.82008\n",
      "Epoch 7/20\n",
      "24320/49738 [=============>................] - ETA: 37s - loss: 3.0197"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-fc62c44c39e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VanillaModel.fit(reshaped_input, onehot_output,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49738/49738 [==============================] - 304s 6ms/step - loss: 2.9634\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.96338, saving model to weights-LSTM-improvement-01-2.9634.hdf5\n",
      "Epoch 2/20\n",
      "49738/49738 [==============================] - 295s 6ms/step - loss: 2.8884\n",
      "\n",
      "Epoch 00002: loss improved from 2.96338 to 2.88842, saving model to weights-LSTM-improvement-02-2.8884.hdf5\n",
      "Epoch 3/20\n",
      "49738/49738 [==============================] - 292s 6ms/step - loss: 2.8215\n",
      "\n",
      "Epoch 00003: loss improved from 2.88842 to 2.82154, saving model to weights-LSTM-improvement-03-2.8215.hdf5\n",
      "Epoch 4/20\n",
      "49738/49738 [==============================] - 312s 6ms/step - loss: 2.7941\n",
      "\n",
      "Epoch 00004: loss improved from 2.82154 to 2.79407, saving model to weights-LSTM-improvement-04-2.7941.hdf5\n",
      "Epoch 5/20\n",
      "49738/49738 [==============================] - 292s 6ms/step - loss: 2.7640\n",
      "\n",
      "Epoch 00005: loss improved from 2.79407 to 2.76402, saving model to weights-LSTM-improvement-05-2.7640.hdf5\n",
      "Epoch 6/20\n",
      "49738/49738 [==============================] - 296s 6ms/step - loss: 2.7256\n",
      "\n",
      "Epoch 00006: loss improved from 2.76402 to 2.72558, saving model to weights-LSTM-improvement-06-2.7256.hdf5\n",
      "Epoch 7/20\n",
      "49738/49738 [==============================] - 298s 6ms/step - loss: 2.6768\n",
      "\n",
      "Epoch 00007: loss improved from 2.72558 to 2.67676, saving model to weights-LSTM-improvement-07-2.6768.hdf5\n",
      "Epoch 8/20\n",
      "49738/49738 [==============================] - 302s 6ms/step - loss: 2.6182\n",
      "\n",
      "Epoch 00008: loss improved from 2.67676 to 2.61825, saving model to weights-LSTM-improvement-08-2.6182.hdf5\n",
      "Epoch 9/20\n",
      "49738/49738 [==============================] - 311s 6ms/step - loss: 2.5490\n",
      "\n",
      "Epoch 00009: loss improved from 2.61825 to 2.54902, saving model to weights-LSTM-improvement-09-2.5490.hdf5\n",
      "Epoch 10/20\n",
      "49738/49738 [==============================] - 315s 6ms/step - loss: 2.4859\n",
      "\n",
      "Epoch 00010: loss improved from 2.54902 to 2.48585, saving model to weights-LSTM-improvement-10-2.4859.hdf5\n",
      "Epoch 11/20\n",
      "49738/49738 [==============================] - 308s 6ms/step - loss: 2.4216\n",
      "\n",
      "Epoch 00011: loss improved from 2.48585 to 2.42161, saving model to weights-LSTM-improvement-11-2.4216.hdf5\n",
      "Epoch 12/20\n",
      "49738/49738 [==============================] - 325s 7ms/step - loss: 2.3613\n",
      "\n",
      "Epoch 00012: loss improved from 2.42161 to 2.36125, saving model to weights-LSTM-improvement-12-2.3613.hdf5\n",
      "Epoch 13/20\n",
      "49738/49738 [==============================] - 324s 7ms/step - loss: 2.3044\n",
      "\n",
      "Epoch 00013: loss improved from 2.36125 to 2.30444, saving model to weights-LSTM-improvement-13-2.3044.hdf5\n",
      "Epoch 14/20\n",
      "49738/49738 [==============================] - 326s 7ms/step - loss: 2.2518\n",
      "\n",
      "Epoch 00014: loss improved from 2.30444 to 2.25183, saving model to weights-LSTM-improvement-14-2.2518.hdf5\n",
      "Epoch 15/20\n",
      "49738/49738 [==============================] - 339s 7ms/step - loss: 2.2022\n",
      "\n",
      "Epoch 00015: loss improved from 2.25183 to 2.20222, saving model to weights-LSTM-improvement-15-2.2022.hdf5\n",
      "Epoch 16/20\n",
      "49738/49738 [==============================] - 356s 7ms/step - loss: 2.1526\n",
      "\n",
      "Epoch 00016: loss improved from 2.20222 to 2.15263, saving model to weights-LSTM-improvement-16-2.1526.hdf5\n",
      "Epoch 17/20\n",
      "49738/49738 [==============================] - 334s 7ms/step - loss: 2.1040\n",
      "\n",
      "Epoch 00017: loss improved from 2.15263 to 2.10396, saving model to weights-LSTM-improvement-17-2.1040.hdf5\n",
      "Epoch 18/20\n",
      "49738/49738 [==============================] - 341s 7ms/step - loss: 2.0620\n",
      "\n",
      "Epoch 00018: loss improved from 2.10396 to 2.06201, saving model to weights-LSTM-improvement-18-2.0620.hdf5\n",
      "Epoch 19/20\n",
      "49738/49738 [==============================] - 312s 6ms/step - loss: 2.0132\n",
      "\n",
      "Epoch 00019: loss improved from 2.06201 to 2.01321, saving model to weights-LSTM-improvement-19-2.0132.hdf5\n",
      "Epoch 20/20\n",
      "49738/49738 [==============================] - 307s 6ms/step - loss: 1.9716\n",
      "\n",
      "Epoch 00020: loss improved from 2.01321 to 1.97158, saving model to weights-LSTM-improvement-20-1.9716.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818325d68>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMModel.fit(reshaped_input, onehot_output,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEED: \n",
      "you're trying to have good programmers. there's no implicit problem that probably be components with a day for startups. but the best startup is choosing that it's really presented unfortunately. we haven't had a few decided model of startups that wouldn'\n",
      "o$vdwwo$vdww$_dew$1d0w$vd1\"6_[$v5w$kw6vd_$v5w[$0w$_dv$v$1w6_'$'5$'wwv$_de$$6_v$vd$kw6f$[de0$wd60$60n$'d0$$ffvww$600w0w$vdw_o$vd$kww$wd1wvv'_2$vd$0w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0d$0w$1d0$$5ww$[deu0w$2d'_2$vd$ w$6 fw$vd$kww$vd$swdo$6f0v$0"
     ]
    }
   ],
   "source": [
    "# Test the model... error didn't improve after a few epochs\n",
    "# load the network weights\n",
    "\n",
    "weightsfile = \"weights-LSTM-improvement-20-1.9716.hdf5\"\n",
    "\n",
    "LSTMModel.load_weights(weightsfile)\n",
    "LSTMModel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "start = np.random.randint(0, len(input_data)-1)\n",
    "pattern = input_data[start]\n",
    "generated = []\n",
    "\n",
    "print(\"RANDOM SEED: \")\n",
    "print(''.join([int2ch[i] for i in pattern]))\n",
    "\n",
    "for i in range(1000):\n",
    "        \n",
    "    inp = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    inp = inp / float(num_vocab)\n",
    "    pred = LSTMModel.predict(inp, verbose=0)\n",
    "    \n",
    "    idx = np.argmax(pred)    \n",
    "    result = int2ch[idx]\n",
    "    sys.stdout.write(result)\n",
    "            \n",
    "    # append the new predicted index\n",
    "    pattern.append(idx)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
